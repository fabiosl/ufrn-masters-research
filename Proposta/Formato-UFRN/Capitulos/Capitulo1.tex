\chapter{Bibliographic Review}\label{bibreviewChap}

The goal of this chapter is to explore the main concepts that are related to our work. We begin by presenting popular concepts, such as Cloud Computing, \textit{Everything as a Service} strategy, NoSQL and Service Level Agreements. 
We also explain how each of these concepts are linked with this work.

\section{Cloud Computing}

Technology evolved with big steps over the last decades. Internet is now a pervasive concept and individuals can be connected virtually everywhere on Earth. \cite{Armbrust09m.:above}

Web applications and IT-based processes followed this evolution and today a number of companies rely on software on its production chain. Information Technology can be a competitive advantage of a company, but it \textbf{might not}  be part of its core business \cite{powell1997information}. In fact, this is a common scenario on a number of successful companies of the current century, as we might notice.

To avoid losing track of its core business, a number of companies now prefer to outsource (part of) their IT department to other companies \cite{quinn2013technology}. In other words, today it is possible to outsource IT infrastructure, product development and even the entire IT department to other companies.

In the late 60's, former Stanford University professor John McCarthy introduced the concept of time-sharing of computing services in a famous speech on time-sharing systems, as referenced by \cite{brendon} and \cite{wiki:mccarthy}. In fact, Prof. McCarthy believed that computer resources would be provided as commodities, like water and electricity.

Several years later, this concept brought to life the notion of \textit{Cloud Computing}, together with new concepts, such as Infrastructure as a Service \textit{(IAAS)}, Platform as a Service \textit{(PAAS)}, Software as a Service \textit{(SAAS)} and Everything as a Service \textit{(XaaS)}~\cite{AViewOfCloudComputing}.

According to~\cite{AViewOfCloudComputing}, \textit{Cloud computing refers to both the applications delivered as services over the Internet and the hardware and systems software in the data centers that provide those services.} 

\cite{stanoevskaslabeva2009grid} outlines some of the features of Cloud Computing:

\begin{itemize}
   \item{Cloud Computing is a new computing paradigm.}
   \item{The main features of clouds are virtualization and scalability on demand.}

   \item{Infrastructure resources (hardware, storage and system software) and applications
        are provided in X-as-a-Service manner.}
   \item{Utility computing and SaaS are delivered in an integrated manner. Computing might be consumed separately.}
   \item{Cloud services are consumed either via Web browser or via a defined API.}
\end{itemize}


The ``pay as you go'' model offered by Cloud providers revolutionized the IT market, enabling companies to consume computing resources that matched its needs. Small companies became more competitive, as there is no more need to build datacentres to scale companies. As professor McCarthy believed, computing resources can now be seen as commodities for a company, just like water and electricity.  

\section{Everything as a Service - XaaS}

Service-Oriented Architecture (SOA) defines several concepts of ``as-a-service'' models. To enumerate a few, it is possible to find mentions to Platform as a Service (PaaS), Infrastructure as a Service (IaaS), Software as a Service (SaaS), Database as a Service (DBaaS), Desktop as a Service (DaaS), Monitoring as a Service (MaaS) and Communication as a Service (CaaS) on the literature. 

To summarize all these concepts, a new term arose: Everything as a service (XaaS)\cite{7214098}\cite{Armbrust09m.:above}.

On the context of Cloud Computing, however, three of these concepts are the most relevant, and we define them more precisely:

\begin{itemize}
   \item{Infrastructure as a service (IaaS): It is the most simple kind of ``as-a-service'' product and is located on the base of the IaaS-PaaS-SaaS Stack (Figure \ref{fig:cloudstach}). IaaS mostly refers to (Virtual) Machines, Storage Devices, Network Infrastructure and other infrastructural services that are available on Cloud Computing vendors.} Some examples of IaaS providers are \cite{amazonec2} \cite{rackspace} and \cite{azure}. 
   \item{Platform as a Service (PaaS): PaaS refers to the development environments that are available from cloud vendors. PaaSs are composed by a development stack, and generally offer databases, web servers and execution runtime. Examples of PaaSs are \cite{beanstalk}, \cite{azure} and \cite{GAE}.  }
   \item{Software as a Service (SaaS): Software as a Service refers to the applications that run on the cloud: Webmail, CRM, Gaming Platforms, Learning Management Systems, etc. SaaSs, just as IaaSs and PaaSs, generally charge its users a periodic fee. The fee is generally conceived in a pay-as-you-go model, so users get charged in a scalable way.  
}

\end{itemize}



\begin{figure}[ht!]
\centering
\includegraphics[width=80mm]{cloud_stack.png}
\caption{IaaS-PaaS-SaaS Stack~\cite{kepes2011understanding}.\label{fig:cloudstach}}
\end{figure}

Since the beginning of the Cloud movement several discussions were held concerning the security of Clouds. \cite{2010security} discusses that the security threats that arise on Cloud Computing are the result of users/enterprise lack of control of the IaaS layer. Not all companies know where their documents/data is physically stored and what are the security instruments that must be used to assure data safety on Cloud environments.

On the base of the pyramid of Figure~\ref{fig:cloudstach} is located the IaaS - machines, Network Infrastructure and other Simple Services. Above IaaS lies the PaaS layer - It acts as a ``middleware'' between the SaaS Layer and the IaaS layer, providing the development environments that developers need to deploy applications. On the top of the image is located the SaaS layer. 

To have a better understanding of the security concerns on Cloud Computing, a deeper understanding of its architecture is needed. Figure~\ref{fig:cloudmodel} illustrates the reference model for cloud computing \cite{alliance2009}.

The IaaS layer is generally composed by five elements: API's, Abstraction, Core Connectivity, Hardware and Facilities. A cloud provider may be vulnerable if a security breach is discovered on its APIs or Abstraction Layer, for example. Another possible vulnerability in cloud providers are outages. In 2014, major cloud providers, such as \cite{amazonec2}, \cite{azure}, \cite{rackspace} and \cite{GAE} experienced downtime \cite{cloudoutageaudit}.

Similar security issues can be found on the PaaS and SaaS layers.

\begin{figure}[ht!]
\centering
\includegraphics[width=80mm]{Imagens/cloudreferencemodel.png}
\caption{Cloud Reference Model ~\cite{alliance2009}.\label{fig:cloudmodel}}
\end{figure}


\section{The technological shift}
The adoption of cloud solutions is growing fast among organizations~\cite{Armbrust09m.:above}.
Centralized (mostly mainframe) technology is being replaced by distributed and more flexible forms of data storage and processing.
This change of paradigm is motivated by the necessity to improve the use of resources, as well as by the increasing velocity in which data is produced.

On the early 90's it was commonplace for every Information Technology (IT) company to have its own Data Center with huge servers and mainframes. 
IT costs were high, and high-performance computing was available only for big companies, as data centers required a large physical infrastructure and have high costs for maintenance~\cite{Armbrust09m.:above}.

The regular way of building a web application was to use a client-server approach, where the server was a powerful (and expensive) machine. 
At the same time, new players, such as Google or Yahoo, were rising with bigger missions: \textit{``to organize the world's information and make it universally accessible and useful''}~\cite{Spector:2012:GHA:2209249.2209262}. 
The popularization of the internet use incentivized new ways of commerce exchange, yielding an explosion in the amount of data produced and exchanged. 
It was \textit{just} impossible to store the petabytes of daily-generated data in a single server. 

From this point on, the community realized the economical convenience of building and maintaining several low-performance servers, instead of a single high-performance one, even if this this requires a change of culture in the administration of the new datacentres. The new approach (scale-out) is also incompatible with the traditional way of building applications (scale-up), that usually were designed to work on a single server and database. Both approaches are represented on Figure~\ref{fig:scaleupout}.

\begin{figure}[ht!]
\centering
\includegraphics[width=100mm]{scaleOut.png}
\caption{Scale Out vs Scale Up.\cite{scaleupref} \label{fig:scaleupout}}
\end{figure}


Several research initiatives were conducted in this area and a common solution was rising: to distribute data storage and processing. 
Google, Yahoo and other big IT players helped to build open source tools to make this approach possible, like Hadoop~\cite{5496972}.



\section{Data Integration, NoSQL Movement \& Polyglot Persistence}

Along with the NoSQL (Not only SQL) movement and expansion of Social Networks, new concepts for Database Models became popular, like Document Store, Search Engines, Key-Value store, Wide Column Store, Multi-Model and Graph DBMS \cite{dbrankingchart}. 

New ways to store and retrieve data are in high demand, as Figure~\ref{fig:popularityDB} suggests. This chart shows trends of popularity growth among categories. As \cite{dbrankingchart} explains: \textit{``In order to allow comparisons, the initial value is normalized to 100. For most of the categories the trend starts with January 2013 but search engines and multivalue DBMS are only collected since February 2013 and May 2013.''}. 



\begin{figure}[ht!]
\centering
\includegraphics[width=150mm]{popularityDB.png}
\caption{Database Popularity Growth Chart \cite{dbrankingchart}.\label{fig:popularityDB}}
\end{figure}

Figure \ref{fig:currentPopularity} presents the current database popularity by categories. It shows that despite of the NoSQL movement, relational databases are still responsible for more than 80\% of the databases used in applications.

\begin{figure}[ht!]
\centering
\includegraphics[width=100mm]{Imagens/DBpie.png}
\caption{Database Popularity Chart \cite{dbrankingchart}.\label{fig:currentPopularity}}
\end{figure}


Today, instead of having a single Relational Database Management System (DBMS) for the whole application, it is efficient and cost-effective to have several Data Base Engines, one for each type of data that the application handles. 
This concept is called \textit{Polyglot Persistence}~\cite{sadalage2012nosql}. In~\cite{dbranking} a ranking of the most popular DB engines is presented.

As \cite{AdressingDataManagementCloud} illustrates, polyglot persistence is very useful in the context of  e-commerce applications that deal with a catalog, user access logs, financial information, shopping carts and purchase transactions, for example.

The notion of polyglot persistence is built upon the observation that the \textit{nature} of each data type is significantly different (i.e: user logs imply high volume of writes on multiple nodes, shopping carts need high availability and user sessions require rapid access for reads and writes). 

As computing services started to decentralize, developers started to build applications that depended of several data-sources. 
By this time the use of Web Services and Service Oriented Architecture (SOA) became more popular~\cite{Armbrust09m.:above}. 



\section{Transitioning Processes}

In 1965 Gordon E. Moore, Intel's co-founder, published a paper stating that the number of components in integrated circuits had doubled every two years, and would continue to do so for the at least another decade \cite{658762}. Today, this statement is known as ``Moore's Law''.

A similar trend is stablished for commercial software. Wirth's law, Gates' law (Microsoft) or Page's law (Google) state that ``the speed of software halves every 18 months'', compensating Moore's law. \cite{wirth1995a}\cite{brinbreaking}

In other words, software components evolve in the opposite direction that hardware evolves. Useful software are usually versioned, updated and patched on a regular basis. As stated by \cite{922739}, maintaining software products is not cheap, and generally consumes on average 60\% of software costs.

Time-to-market (TTM) is the length of time that takes for from a product being conceived until its available for sale. Minimum-Viable-Product (MVP) is the product with the highest return on investment versus risk \cite{blank2013four}. Building a MVP and selling it should be the primary goal of a startup \cite{blank2013four}. 

The current economy demands faster shipping of software products in order to meet the desired TTM of software products and to deploy MVPs in less time. Cloud computing and Agile Methods made software development and deployment faster, cheaper and easier for a number of companies. 

One of the points of the 12 principles of the Agile Manifesto \cite{fowler2001agile} is \textit{``Deliver working software frequently, from a couple of weeks to a couple of months, with a preference to the shorter timescale''}.

This need for speed on software delivery has its downsides, however. Decisions must be made by the IT department on a short time schedule, sometimes leaving not enough time to make the best choices on the technologies that should be used on a software product. This and other factors often leads to a software migration, replacement or transitioning scenario. In this scenario (part of) a software is replaced with a more suitable alternative.

In the context of Service-Oriented Architecture this might be seen as the replacement of a Service. In a Multitier architecture scenario this might be seen as the replacement of an entire layer. In fact, basically any component of a \textbf{modular} software can be replaced, migrated or upgraded. 

Examples of Software migrations are numerous on the industry. To number a few: 
\begin{itemize}
\item{Spotify migrated their user base from Postgres to Cassandra\cite{spotifyEngineering}}
\item{Google moved from MySQL to MariaDB \cite{googleMariaDB}}
\item{Twitter moved from Ruby-On-Rails to Java \cite{twitterRails}}
\end{itemize}

Our work focuses specifically on Database Transitioning scenarios. We propose a set of guidelines to justify and guide the transitions from RDBMs to NoSQL databases;

\section{Systematic Mappings}
According to \cite{Petersen:2008:SMS:2227115.2227123}, ``\textit{A software engineering systematic map is a defined method to build a classification scheme and structure a software engineering field of interest.}''
Systematic Mapping studies provide a global view of a given research field and identify the quantity, results, and the kinds of researches in this field.

A Systematic mapping study is composed by a number of steps (Figure~\ref{fig:sms}).
\begin{figure}[ht!]
\centering
\includegraphics[width=100mm]{Imagens/pic1.png}
\caption{Systematic Mapping Steps~\cite{Petersen:2008:SMS:2227115.2227123}.\label{fig:sms}}
\end{figure}

On the first step, \textit{Definition of Research question}, the questions that must be answered on the survey are defined. 
On the \textit{Review Scope} step, researchers target the papers/journal sources that will be taken into consideration on the systematic map. 
After that, the \textit{Search} step is done using a set of predefined search engines and a body of papers (\textit{All papers}) is retrieved. 

After an initial \textit{Screening of the papers}, the \textit{Relevant papers} are chosen according to inclusion and exclusion criteria defined by the research team. 
At this point, the papers that will participate of the study are selected. 
The selection is based on the title, abstracts and keywords of each paper (\textit{Keywording using Abstracts}).

After that, a \textit{Classification Scheme} is built, defining different points-of-view (or facets) from which the body of papers will be classified. 
After matching each paper with the classification schema (\textit{Data Extraction and Mapping Process}), the  systematic mapping is performed.
In this phase the relationships between the collected data (in the light of the classification scheme) are used to answer the research questions.

In \cite{fabioMartinSM} a Systematic mapping study was developed to investigate the use of Service-Level-Agreements (SLAs) on database-transitioning scenarios and to verify how SLAs can be used in this processes. The results of this study are presented in Section \ref{oursystematicmapping}.

\section{Service Level Agreements (SLAs)}

In the field of Law, a contract (or agreement) is generally a written document concerning any point of interest between two parties, each of whom intends to create legal obligations between them. In business environments, contracts are highly necessary to avoid unpleasant situations between a provider and a consumer. 

In the context of service provisioning, it is common to refer to contracts (or agreements) as ``Service-Level agreements'' (SLA's), as the name suggests.  

According to \textit{ITILv3's} official glossary \cite{itilv3glossary}, a Service Level Agreement (SLA) is ``\textit{an agreement between an IT service provider and a customer. 
A service level agreement describes the IT service, documents service level targets, and specifies the responsibilities of the IT service provider and the customer.}'' 

The agreement consists on a set of measurable constraints that a service provider must guarantee to its customers.
In practical terms, it is a document that a service provider delivers to its consumers with minimum quality of service (QoS) metrics. 
If the service is delivered with a lower QoS than is promised on the SLA, consumers may be refunded or earn benefits that were accorded beforehand. 

In the next subsection we present the life-cycle of an SLA, explaining in details each step of it. 

\subsection{The Life-Cycle of an SLA}

The Life-cycle of an SLA consists on six steps, as presented on Figure~\ref{fig:sla-lifecycle}. Each step is explained in the following subsections. 

\begin{figure}[ht!]
\centering
\includegraphics[width=90mm]{Imagens/sla-lifecycle.png}
\caption{SLA Life-cycle \cite{wu2012service}}.\label{fig:sla-lifecycle}
\end{figure}

\subsubsection{Discover Service Provider}
On the first step \textit{(Discover Service Provider)}, a consumer tipically discovers several service providers that may fulfill its needs on a specific scenario. On the domain of Web Services, \textit{Universal Description, Discovery, and Integration} (UDDI) can be used to retrieve a list of web services that might be used to achieve a goal, for example. 

In a Cloud Computing scenario, it is possible to buy computing services from a number of providers, and a cloud-service broker could be used to retrieve a list of available providers. This scenario is very common in cloud computing auctions \cite{7145493}, a new concept that arised with cloud computing and was made possible by companies like Hetzner.com, a company that hosts regular auctions of its computing resources.


\subsubsection{Define SLA}
The second step of the SLA life-cycle \textit{(To Define SLA)} is when an SLA is proposed by the provider. Several works, such as \cite{6846456} and \cite{kouki:hal-00675077} address the issue of specifying an SLA. WS-Agreement \cite{citeulike:2805191} and WSLA \cite{4578560} are very important works on this area. As it is presented on \cite{fabioMartinSM}, there are several ways to specify SLA, but none of them are considered a de-facto standard. 

\cite{fabioMartinSM} also shows that there are several ways to represent an SLA. To enumarate a few, it is possible to represent an SLA as a \textit{i) a natural-language document}, and \textit{ii) an ontology} \textit{automated test suite (unit tests, integration tests)}.

\subsubsection{Establish Agreement}

As stated on the beginning of this secttion, an SLA is a contract between a provider and a consumer. The points of interest of this contract are known as \textit{Service-Level Objectives} (SLOs).

According to \cite{sturm2000foundations}, SLOs must respect a series of features. They must be \textit{Attainable},  \textit{Repeatable},  \textit{Measurable},  \textit{Understandable},  \textit{Meaningful},  \textit{Controllable},  \textit{Affordable} and \textit{Mutually acceptable}. 

Each SLA may explicitly define the ``hardness'' of its SLOs in terms of time. In other words, an SLA can specify what is the fault tolerance rate of each of its SLOs. 

An example can be given to clarify this concept: Two telecommunication companies may have different SLAs regarding the uptime of their services given a fixed period of time. \textbf{Company A} may assure that their uptime is 99.9\% of the time under the period of a year, and \textbf{Company B} may assure that their uptime is 99.99\%. 

In this scenario, it is said that the SLA of Company B is ``harder'' than the SLA of Company A. Figure~\ref{fig:sla-agreement} compares the Availability SLO defined in SLAs of some popular cloud services.

\begin{figure}[ht!]
\centering
\includegraphics[width=120mm]{slo-cloudServices.png}
\caption{Service Level Objective: Availability on Cloud Services \cite{locawebsla}\cite{composesla}\cite{amazonrdssla}}\label{fig:sla-agreement}
\end{figure}

After chosing the service and defining the SLOs, SLA might be established between a consumer and the provider - the third step of th SLA life-cycle. 

\subsubsection{Monitor SLA violation}
The fourth step \textit{(Monitor SLA violation)} is one of the most important on the SLA life-cycle. It is in this step where the consumer protects himself against unfulfilled SLOs. 

Several frameworks and processes might be used to measure and monitor SLA violation. As SLAs do not present a standard way for representation, it is also difficult to find a standardized way to monitor SLA violation. 

\cite{ranna2008} presents three ``monitoring-models'' for SLA violation: 

\begin{itemize}
   \item{\textit{All-or-nothing}: In a all-or-nothing situation, \textbf{all} the SLOs must be satisfied to guarantee that the SLA is still valid.}
   \item{\textit{Partial}: In a partial scenario, the SLA specifies what are the SLOs that may not be broken, and declares rules less important SLOs.}
   \item{\textit{Wheighted Partial}: In a wheighted partial scenario, the consumer and provider specify thresholds that must be met for specific SLOs. If the service quality drops below a threshold, a penalty can be applied. 
}

\end{itemize}

In the context of Web Apps it is also possible to monitor SLA violations with the help of web applications, such as \cite{datadog}, \cite{appsee} and \cite{newrelic}. These tools offer graphical dashboards and alerts when SLAs defined by the software team are violated. The tools are able to monitor the three layers of a web application: front-end, business logic and databases. AJAX calls, plugins and server daemons are used to monitor each part of the web stack. 

\subsubsection{Terminate SLA}
An important question of the life-cycle of a SLA (fith step) is \textit{when} the termination of an SLA is needed. If the termination is due to an SLA violation, it is important to know what party broke the SLA and what are the consequences for the parts.

These situations must be explicitly declared in the initial SLA to avoid unpleasant situations between the provider and the consumer in the future.

\subsubsection{Enforce Penalties for SLA violation}
The sixth step \textit{(Enforce penalties for SLA violation)} can be performed if the penalties that were previously defined are being hit in a regular basis or if both parties of the SLA agree. Several works, as \cite{Lee:2010:PSR:1844765.1845204} propose penalty models/processes for SLA violations. These processes can be analyzed and used by the SLA parties. 

\section{Our Systematic Mapping}\label{oursystematicmapping}

To provide us a better understanding over the use of SLAs in component / service migrations, we have performed a Systematic Mapping study to assess the use of SLAs in database transition scenarios, specifically on migrations from relational databases with NoSQL ones. 

This study is available on Appendix \ref{appendix}. 

\subsection{Identified problems}

As a result, we have analyzed over 70 publications closely related to the use of SLAs in migration scenarios. The study revealed a number of interesting outcomes, and we emphasize two of them below:

\begin{itemize}
\item{No publication was found addressing the problem of measuring the overall improvements after a database transition. Several benchmarking frameworks, such as TPC-H, TPC-DS and YCSB were identified \cite{6616442} during our survey, though. These benchmarking frameworks could be a good starting point to develop new tools and specialized frameworks to solve this problem and might be used in our study to validate that a migration was successful.
}

\item{ \cite{6253526}, \cite{6461875}, \cite{6511780} and \cite{Xiong:2011:APA:2038916.2038931} propose SLA-centric/User-Centric solutions to monitor the performance of web applications. All these solutions are technology-agnostic and could be used to monitor the performance improvements promised by a database transitioning process. Industry experts also pointed out that there are some services, such as New Relic~\cite{newrelic}, Appsee~\cite{appsee} and Datadog~\cite{datadog} that provide SLA-monitoring tools for web apps. 

The systematic mapping revealed no open source solution to monitor Application SLAs in a user-centered view (application level).  
}

\end{itemize}



